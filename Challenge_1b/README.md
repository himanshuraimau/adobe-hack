# PDF Analysis System - Persona-Driven Document Intelligence

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-ready-blue.svg)](https://www.docker.com/)
[![CPU Only](https://img.shields.io/badge/cpu-only-green.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)

## ğŸ¯ Overview

An intelligent document analysis system that extracts and prioritizes the most relevant sections from PDF collections based on specific personas and their job-to-be-done. Built for **Challenge 1B: Persona-Driven Document Intelligence**.

### ğŸš€ Key Features

- **ğŸ§  Semantic Understanding**: Uses sentence transformers for true semantic similarity matching
- **ğŸ‘¤ Persona-Driven**: Tailors content extraction to specific user roles and tasks
- **ğŸ“Š Intelligent Ranking**: Ranks sections by relevance with mathematical precision
- **ğŸ” Granular Analysis**: Sentence-level extraction from top-ranked sections
- **âš¡ High Performance**: Processes documents in under 60 seconds
- **ğŸ³ Docker Ready**: Production-ready containerization
- **ğŸ›¡ï¸ Robust**: Comprehensive error handling and logging

## ğŸ“ Project Structure

```
pdf-analysis-system/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ pdf_analysis/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ collection_processor.py    # Main orchestration
â”‚       â”œâ”€â”€ pdf_analyzer.py           # PDF text extraction
â”‚       â”œâ”€â”€ semantic_ranker.py        # Semantic similarity ranking
â”‚       â””â”€â”€ output_generator.py       # JSON output formatting
â”œâ”€â”€ Collection 1/                     # Travel Planning
â”œâ”€â”€ Collection 2/                     # HR Forms Management
â”œâ”€â”€ Collection 3/                     # Food Menu Planning
â”œâ”€â”€ logs/                            # System logs
â”œâ”€â”€ main.py                          # Entry point
â”œâ”€â”€ requirements.txt                 # Dependencies
â”œâ”€â”€ Dockerfile                       # Container setup
â”œâ”€â”€ approach_explanation.md          # Methodology
â”œâ”€â”€ EXECUTION_INSTRUCTIONS.md        # Usage guide
â””â”€â”€ README.md                        # This file
```

## ğŸƒâ€â™‚ï¸ Quick Start

### Option 1: Docker (Recommended)

```bash
# Build the image
docker build --platform linux/amd64 -t pdf-analysis-system .

# Run with your collections
docker run --rm -v $(pwd):/app/input pdf-analysis-system
```

### Option 2: Direct Python

```bash
# Install dependencies
pip install -r requirements.txt

# Run the system
python main.py
```

## ğŸ“Š Sample Collections

### Collection 1: Travel Planning ğŸŒ
- **Persona**: Travel Planner
- **Task**: Plan a 4-day trip for 10 college friends
- **Documents**: 7 South of France travel guides
- **Output**: Ranked travel tips, activities, and planning advice

### Collection 2: HR Forms Management ğŸ“‹
- **Persona**: HR Professional  
- **Task**: Create and manage fillable forms for onboarding
- **Documents**: 15 Adobe Acrobat tutorials
- **Output**: Form creation and compliance guidance

### Collection 3: Food Menu Planning ğŸ½ï¸
- **Persona**: Food Contractor
- **Task**: Prepare vegetarian buffet menu with gluten-free options
- **Documents**: 9 recipe and cooking guides
- **Output**: Vegetarian recipes and dietary accommodation tips

## ğŸ”§ Technical Specifications

### System Requirements
- **CPU**: Multi-core recommended (uses up to 4 threads)
- **RAM**: Minimum 2GB, 4GB+ recommended
- **Storage**: ~500MB for model cache + document space
- **OS**: Linux, macOS, Windows (cross-platform)

### Performance Metrics
- **Processing Speed**: ~1 second per document
- **Model Size**: 90MB (all-MiniLM-L6-v2)
- **Memory Usage**: Efficient batch processing
- **Success Rate**: 100% across test collections

### Constraints Compliance
- âœ… **CPU Only**: No GPU dependencies
- âœ… **Model Size**: 90MB << 1GB limit
- âœ… **Processing Time**: ~32 seconds << 60 seconds limit
- âœ… **Offline Operation**: Works without internet after setup

## ğŸ“‹ Input/Output Format

### Input Structure
```json
{
  "challenge_info": {
    "challenge_name": "Challenge 1B"
  },
  "documents": [
    {"filename": "document.pdf"}
  ],
  "persona": {
    "role": "Your persona description"
  },
  "job_to_be_done": {
    "task": "Your specific task"
  }
}
```

### Output Structure
```json
{
  "metadata": {
    "input_documents": ["document.pdf"],
    "persona": "Your persona",
    "job_to_be_done": "Your task",
    "processing_timestamp": "2025-01-28T12:00:00"
  },
  "extracted_sections": [
    {
      "document": "document.pdf",
      "section_title": "Section Title",
      "importance_rank": 1,
      "page_number": 5
    }
  ],
  "subsection_analysis": [
    {
      "document": "document.pdf", 
      "refined_text": "Most relevant sentences...",
      "page_number": 5
    }
  ]
}
```

## ğŸ§  Methodology

Our approach combines modern NLP with efficient document processing:

1. **Document Processing**: PyMuPDF for robust PDF text extraction
2. **Section Identification**: Font analysis and layout heuristics
3. **Semantic Embedding**: all-MiniLM-L6-v2 sentence transformer
4. **Relevance Ranking**: Cosine similarity between query and sections
5. **Granular Analysis**: Sentence-level extraction from top sections

See [approach_explanation.md](approach_explanation.md) for detailed methodology.

## ğŸ³ Docker Features

- **Multi-stage build** for optimized image size
- **Pre-cached model** for offline operation
- **Security** with non-root user execution
- **Volume mounting** for flexible data handling
- **Health checks** for monitoring
- **CPU optimization** with proper environment variables

## ğŸ“ˆ Performance Results

```
Total collections found: 3
Successfully processed: 3
Failed to process: 0
Total documents processed: 31
Total sections extracted: 3025
Total processing time: 32.87 seconds
Average time per document: 1.06 seconds
```

## ğŸ” Usage Examples

### Basic Usage
```bash
python main.py
```

### Custom Directory
```bash
python main.py --base-path /path/to/collections --log-level DEBUG
```

### Docker with Custom Volumes
```bash
docker run --rm \
  -v /path/to/input:/app/input \
  -v /path/to/output:/app/output \
  pdf-analysis-system
```

## ğŸ§ª Testing

Run the integration tests:
```bash
python test_integration_final.py
```

## ğŸ“š Documentation

- [EXECUTION_INSTRUCTIONS.md](EXECUTION_INSTRUCTIONS.md) - Detailed setup and usage
- [approach_explanation.md](approach_explanation.md) - Technical methodology
- [REQUIREMENTS_COMPLIANCE.md](REQUIREMENTS_COMPLIANCE.md) - Requirements verification

## ğŸ› ï¸ Development

### Dependencies
- **PyMuPDF**: PDF text extraction
- **sentence-transformers**: Semantic embeddings
- **scikit-learn**: Similarity calculations
- **numpy**: Numerical operations
- **psutil**: System monitoring

### Architecture
- **Modular Design**: Separate components for each processing stage
- **Error Handling**: Comprehensive error recovery
- **Logging**: Detailed progress tracking
- **Batch Processing**: Memory-efficient operation

## ğŸ† Challenge Compliance

This system fully complies with all Challenge 1B requirements:

- âœ… **Section Relevance (60 points)**: Semantic similarity ranking
- âœ… **Sub-Section Relevance (40 points)**: Granular sentence analysis
- âœ… **Technical Constraints**: CPU-only, <1GB model, <60s processing
- âœ… **Output Format**: Exact JSON structure compliance
- âœ… **Deliverables**: All required files and documentation

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

**Built for Adobe India Hackathon 2025 - Challenge 1B: Persona-Driven Document Intelligence** 